{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvsKe2MP6hI1vQfvw4HRN4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suriarasai/BEAD2026/blob/main/colab/03d_Functional_PySpark_UseCase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark Data Cleansing Tutorial: Singapore Manufacturing Equipment Data\n",
        "\n",
        "This notebook demonstrates a Use Case with:\n",
        "1. Core RDD functions (map, filter, reduce, flatMap, groupByKey, reduceByKey)\n",
        "2. User-Defined Functions (UDFs)\n",
        "3. Higher-Order Functions\n",
        "4. Currying\n",
        "5. Real-world data cleansing scenarios\n",
        "\n",
        "## Context\n",
        "\n",
        "Equipment sensor data from Singapore Manufacturing Plants."
      ],
      "metadata": {
        "id": "k5Ag-0scQV79"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fae3bda"
      },
      "source": [
        "This cell imports several essential modules for the PySpark data cleansing tutorial:\n",
        "\n",
        "*   `from pyspark import SparkContext, SparkConf`: These are fundamental classes from the PySpark library. `SparkContext` is the entry point for Spark functionality, allowing you to create RDDs (Resilient Distributed Datasets) and interact with the Spark cluster. `SparkConf` is used to configure various Spark parameters, such as the application name and master URL.\n",
        "*   `from datetime import datetime`: This imports the `datetime` class from Python's built-in `datetime` module, which is crucial for working with dates and times, including parsing, formatting, and performing calculations on date/time objects.\n",
        "*   `import re`: This imports Python's built-in `re` module, which provides regular expression operations. It's often used for pattern matching and text manipulation, useful in data cleansing for tasks like extracting specific patterns or validating strings.\n",
        "*   `from functools import reduce`: This imports the `reduce` function from the `functools` module. `reduce` applies a given function to the items of an iterable in a cumulative way, from left to right, to reduce the iterable to a single output. It's a powerful tool for aggregation.\n",
        "*   `from typing import Callable, List, Tuple, Optional`: These are type hints from Python's `typing` module. They are used to specify the expected types of function arguments and return values, enhancing code readability, maintainability, and enabling static analysis tools to catch potential errors early."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hwd7uOu5QFzl"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from datetime import datetime\n",
        "import re\n",
        "from functools import reduce\n",
        "from typing import Callable, List, Tuple, Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Context\n",
        "\n"
      ],
      "metadata": {
        "id": "QuciHh_gQscJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Context\n",
        "conf = SparkConf().setAppName(\"SingaporeEquipmentDataCleansing\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "h6VeYaUBQz3d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Raw equipment data with typical data quality issues:\n",
        "- Inconsistent date formats\n",
        "- Missing values\n",
        "- Inconsistent location formats\n",
        "- Temperature in different units (Celsius/Fahrenheit)\n",
        "- Whitespace issues\n",
        "- Invalid sensor readings\n"
      ],
      "metadata": {
        "id": "YLYqqOk-Q1J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_equipment_data = [\n",
        "    \"EQ001|CNC-MILLING-001|Jurong Industrial Estate|25-12-2024 14:30|85.5|CELSIUS|NORMAL|  \",\n",
        "    \"EQ002|HYDRAULIC-PRESS-042|   Tuas South Ave 3   |2024/12/25 15:45|187.2|FAHRENHEIT|ALERT|Oil Pressure Low\",\n",
        "    \"EQ003|ROBOTIC-ARM-123|Woodlands Industrial Park|25/12/2024 16:00|78.0|CELSIUS||Sensor offline\",\n",
        "    \"EQ004|INJECTION-MOLD-099|Changi Business Park|25-12-2024 16:15|NULL|CELSIUS|NORMAL|\",\n",
        "    \"EQ005|LATHE-MACHINE-067|Ang Mo Kio Industrial Park 2|2024-12-25 17:00|92.3|CELSIUS|WARNING|Vibration detected\",\n",
        "    \"EQ006|CONVEYOR-SYSTEM-221|Jurong Industrial Estate|25/12/2024|75.5|FAHRENHEIT|NORMAL|\",\n",
        "    \"EQ007|WELDING-ROBOT-456|Tuas South Ave 3|25-12-2024 18:30|-999|CELSIUS|ERROR|Temperature sensor fault\",\n",
        "    \"EQ008||Woodlands Industrial Park|25-12-2024 19:00|88.1|CELSIUS|NORMAL|\",\n",
        "    \"EQ009|CUTTING-MACHINE-789|Changi Business Park|2024/12/25 19:30|95.0|CELSIUS|WARNING|Blade wear detected\",\n",
        "    \"EQ010|PACKAGING-UNIT-334|Clementi Loop|INVALID_DATE|82.5|CELSIUS|NORMAL|\",\n",
        "]"
      ],
      "metadata": {
        "id": "a67B4fb0Q3dz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create RDD from raw data"
      ],
      "metadata": {
        "id": "D7zKxvmQSwj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equipment_rdd = sc.parallelize(raw_equipment_data)\n",
        "\n",
        "print(\"\\nRaw Equipment Data Sample:\")\n",
        "for record in equipment_rdd.take(5):\n",
        "    print(record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLynSC5OSqdZ",
        "outputId": "e9dd414c-628e-4f31-ca1e-ed48ca2d0860"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw Equipment Data Sample:\n",
            "EQ001|CNC-MILLING-001|Jurong Industrial Estate|25-12-2024 14:30|85.5|CELSIUS|NORMAL|  \n",
            "EQ002|HYDRAULIC-PRESS-042|   Tuas South Ave 3   |2024/12/25 15:45|187.2|FAHRENHEIT|ALERT|Oil Pressure Low\n",
            "EQ003|ROBOTIC-ARM-123|Woodlands Industrial Park|25/12/2024 16:00|78.0|CELSIUS||Sensor offline\n",
            "EQ004|INJECTION-MOLD-099|Changi Business Park|25-12-2024 16:15|NULL|CELSIUS|NORMAL|\n",
            "EQ005|LATHE-MACHINE-067|Ang Mo Kio Industrial Park 2|2024-12-25 17:00|92.3|CELSIUS|WARNING|Vibration detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Core Functions\n",
        "\n",
        "This sample code uses map, filters and flatmap.\n",
        "\n",
        "### Map and Tuples"
      ],
      "metadata": {
        "id": "3xChPUnkSzvD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3359ab56"
      },
      "source": [
        "This cell defines a function `parse_equipment_record` which takes a single string `record` (expected to be pipe-delimited) and splits it into individual fields. It then uses a generator expression `(field.strip() for field in fields)` to remove leading/trailing whitespace from each field and converts the result into a `tuple`.\n",
        "\n",
        "The `equipment_rdd.map(parse_equipment_record)` line applies this `parse_equipment_record` function to every element in the `equipment_rdd`. The `map` transformation is a core Spark operation that applies a function to each element of an RDD, returning a new RDD. Here, it transforms each raw string record into a tuple of cleaned fields, creating the `parsed_rdd`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_equipment_record(record: str) -> tuple:\n",
        "    \"\"\"Parse pipe-delimited equipment record into tuple\"\"\"\n",
        "    fields = record.split('|')\n",
        "    return tuple(field.strip() for field in fields)\n",
        "\n",
        "parsed_rdd = equipment_rdd.map(parse_equipment_record)\n",
        "\n",
        "print(\"Parsed Records (first 3):\")\n",
        "for record in parsed_rdd.take(3):\n",
        "    print(record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8miSBjF_TDXk",
        "outputId": "9f75c4a7-bcea-4972-b126-34c067e472a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed Records (first 3):\n",
            "('EQ001', 'CNC-MILLING-001', 'Jurong Industrial Estate', '25-12-2024 14:30', '85.5', 'CELSIUS', 'NORMAL', '')\n",
            "('EQ002', 'HYDRAULIC-PRESS-042', 'Tuas South Ave 3', '2024/12/25 15:45', '187.2', 'FAHRENHEIT', 'ALERT', 'Oil Pressure Low')\n",
            "('EQ003', 'ROBOTIC-ARM-123', 'Woodlands Industrial Park', '25/12/2024 16:00', '78.0', 'CELSIUS', '', 'Sensor offline')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filters\n"
      ],
      "metadata": {
        "id": "FqYsY_ZuTGGC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea6b4673"
      },
      "source": [
        "This cell defines a function `is_valid_record` to check if a parsed record meets basic validity criteria. Specifically, it verifies that the record has a minimum number of fields and that essential fields (equipment_id, equipment_type, location) are not empty. It also checks for the presence of 'INVALID' in the timestamp.\n",
        "\n",
        "The `valid_rdd = parsed_rdd.filter(is_valid_record)` line applies this validation function to every record in the `parsed_rdd`. The `filter` transformation is a core Spark operation that returns a new RDD containing only the elements for which the given function returns `True`. The cell then prints the counts of total, valid, and removed records to quantify the data quality improvement."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_record(record: tuple) -> bool:\n",
        "    \"\"\"Check if equipment record has minimum required fields\"\"\"\n",
        "    # Must have at least: equipment_id, equipment_type, location, timestamp\n",
        "    if len(record) < 8:\n",
        "        return False\n",
        "\n",
        "    equipment_id, equipment_type, location, timestamp = record[0:4]\n",
        "\n",
        "    # Check for essential fields\n",
        "    if not equipment_id or not equipment_type or not location:\n",
        "        return False\n",
        "\n",
        "    # Check for invalid timestamp\n",
        "    if 'INVALID' in timestamp.upper():\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "valid_rdd = parsed_rdd.filter(is_valid_record)\n",
        "\n",
        "print(f\"Total records: {parsed_rdd.count()}\")\n",
        "print(f\"Valid records: {valid_rdd.count()}\")\n",
        "print(f\"Invalid records removed: {parsed_rdd.count() - valid_rdd.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgrYKaYvTHp0",
        "outputId": "134bd070-dfc8-49c7-9533-2bfd1759aa71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total records: 10\n",
            "Valid records: 8\n",
            "Invalid records removed: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FlatMap\n",
        "\n"
      ],
      "metadata": {
        "id": "1ALHEvfzTMT_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71493370"
      },
      "source": [
        "This cell defines `extract_location_words` to extract significant words from the location field of a record. It then uses `flatMap()` on `valid_rdd` to get a new RDD where each record's location words are flattened into individual elements, followed by `distinct()` to find unique location keywords."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_location_words(record: tuple) -> List[str]:\n",
        "    \"\"\"Extract individual words from location field\"\"\"\n",
        "    location = record[2]\n",
        "    # Split by spaces and filter out common words\n",
        "    words = location.split()\n",
        "    return [word for word in words if len(word) > 3]\n",
        "\n",
        "location_words_rdd = valid_rdd.flatMap(extract_location_words)\n",
        "\n",
        "print(\"Unique location keywords:\")\n",
        "unique_locations = location_words_rdd.distinct().collect()\n",
        "print(unique_locations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgryARdFTOBZ",
        "outputId": "4c35e41e-115e-427a-a7bd-a351a3926e4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique location keywords:\n",
            "['Industrial', 'Tuas', 'Changi', 'Jurong', 'Estate', 'South', 'Woodlands', 'Park', 'Business']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Defined Functions\n",
        "\n",
        "\n",
        "### Data Normalization using UDF\n"
      ],
      "metadata": {
        "id": "4qIRqWYLTUZV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc11f996"
      },
      "source": [
        "This cell introduces two functions: `normalize_date` which converts various date string formats to a standard ISO format, and `apply_date_normalization` which applies this conversion to the timestamp field of each record. The `map()` transformation creates `normalized_date_rdd`, and examples are printed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_date(date_str: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Normalize various date formats to ISO format (YYYY-MM-DD HH:MM)\n",
        "    Handles: DD-MM-YYYY, YYYY/MM/DD, DD/MM/YYYY\n",
        "    \"\"\"\n",
        "    if not date_str or 'INVALID' in date_str.upper():\n",
        "        return None\n",
        "\n",
        "    # Try different date formats\n",
        "    formats = [\n",
        "        '%d-%m-%Y %H:%M',      # 25-12-2024 14:30\n",
        "        '%Y/%m/%d %H:%M',      # 2024/12/25 15:45\n",
        "        '%d/%m/%Y %H:%M',      # 25/12/2024 16:00\n",
        "        '%Y-%m-%d %H:%M',      # 2024-12-25 17:00\n",
        "        '%d-%m-%Y',            # 25-12-2024 (no time)\n",
        "        '%d/%m/%Y',            # 25/12/2024 (no time)\n",
        "    ]\n",
        "\n",
        "    for fmt in formats:\n",
        "        try:\n",
        "            dt = datetime.strptime(date_str.strip(), fmt)\n",
        "            return dt.strftime('%Y-%m-%d %H:%M')\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    return None\n",
        "\n",
        "def apply_date_normalization(record: tuple) -> tuple:\n",
        "    \"\"\"Apply date normalization to record\"\"\"\n",
        "    record_list = list(record)\n",
        "    record_list[3] = normalize_date(record_list[3])\n",
        "    return tuple(record_list)\n",
        "\n",
        "normalized_date_rdd = valid_rdd.map(apply_date_normalization)\n",
        "\n",
        "print(\"Date Normalization Examples:\")\n",
        "for record in normalized_date_rdd.take(3):\n",
        "    print(f\"Equipment: {record[0]}, Normalized Date: {record[3]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlbr8VbZTgE6",
        "outputId": "c81d08ad-247f-4a2b-da69-2b64c344269a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date Normalization Examples:\n",
            "Equipment: EQ001, Normalized Date: 2024-12-25 14:30\n",
            "Equipment: EQ002, Normalized Date: 2024-12-25 15:45\n",
            "Equipment: EQ003, Normalized Date: 2024-12-25 16:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature Conversion UDF\n",
        "\n"
      ],
      "metadata": {
        "id": "NIbQn_LHTg-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fahrenheit_to_celsius(fahrenheit: float) -> float:\n",
        "    \"\"\"Convert Fahrenheit to Celsius\"\"\"\n",
        "    return (fahrenheit - 32) * 5.0 / 9.0\n",
        "\n",
        "def normalize_temperature(record: tuple) -> tuple:\n",
        "    \"\"\"\n",
        "    Normalize temperature to Celsius and handle invalid readings\n",
        "    Invalid readings: NULL, -999, or out of range\n",
        "    \"\"\"\n",
        "    record_list = list(record)\n",
        "    temp_str = record_list[4]\n",
        "    unit = record_list[5]\n",
        "\n",
        "    # Handle NULL or invalid values\n",
        "    if temp_str == 'NULL' or temp_str == '-999':\n",
        "        record_list[4] = None\n",
        "        record_list[5] = 'CELSIUS'\n",
        "        return tuple(record_list)\n",
        "\n",
        "    try:\n",
        "        temp = float(temp_str)\n",
        "\n",
        "        # Convert Fahrenheit to Celsius\n",
        "        if unit == 'FAHRENHEIT':\n",
        "            temp = fahrenheit_to_celsius(temp)\n",
        "            record_list[5] = 'CELSIUS'\n",
        "\n",
        "        # Validate reasonable temperature range (0-150°C for machinery)\n",
        "        if temp < 0 or temp > 150:\n",
        "            record_list[4] = None\n",
        "        else:\n",
        "            record_list[4] = round(temp, 2)\n",
        "\n",
        "    except ValueError:\n",
        "        record_list[4] = None\n",
        "\n",
        "    return tuple(record_list)\n",
        "\n",
        "normalized_temp_rdd = normalized_date_rdd.map(normalize_temperature)\n",
        "\n",
        "print(\"Temperature Normalization Examples:\")\n",
        "for record in normalized_temp_rdd.take(5):\n",
        "    print(f\"Equipment: {record[0]}, Temp: {record[4]}°C, Status: {record[6]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb8OPC8GToGN",
        "outputId": "640f1c44-cf37-42d1-e14b-48b68b9f1455"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature Normalization Examples:\n",
            "Equipment: EQ001, Temp: 85.5°C, Status: NORMAL\n",
            "Equipment: EQ002, Temp: 86.22°C, Status: ALERT\n",
            "Equipment: EQ003, Temp: 78.0°C, Status: \n",
            "Equipment: EQ004, Temp: None°C, Status: NORMAL\n",
            "Equipment: EQ005, Temp: 92.3°C, Status: WARNING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Location Standardization UDF"
      ],
      "metadata": {
        "id": "2QAQhApaTrit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_location(location: str) -> str:\n",
        "    \"\"\"\n",
        "    Standardize Singapore industrial location names\n",
        "    \"\"\"\n",
        "    location = location.strip()\n",
        "\n",
        "    # Standardization rules for common Singapore industrial areas\n",
        "    standardization_map = {\n",
        "        'Jurong Industrial Estate': 'JURONG_IE',\n",
        "        'Tuas South Ave 3': 'TUAS_SOUTH',\n",
        "        'Tuas South': 'TUAS_SOUTH',\n",
        "        'Woodlands Industrial Park': 'WOODLANDS_IP',\n",
        "        'Changi Business Park': 'CHANGI_BP',\n",
        "        'Ang Mo Kio Industrial Park 2': 'AMK_IP2',\n",
        "        'Clementi Loop': 'CLEMENTI',\n",
        "    }\n",
        "\n",
        "    for key, value in standardization_map.items():\n",
        "        if key.lower() in location.lower():\n",
        "            return value\n",
        "\n",
        "    return location.upper().replace(' ', '_')\n",
        "\n",
        "def apply_location_standardization(record: tuple) -> tuple:\n",
        "    \"\"\"Apply location standardization to record\"\"\"\n",
        "    record_list = list(record)\n",
        "    record_list[2] = standardize_location(record_list[2])\n",
        "    return tuple(record_list)\n",
        "\n",
        "standardized_rdd = normalized_temp_rdd.map(apply_location_standardization)\n",
        "\n",
        "print(\"Location Standardization Examples:\")\n",
        "for record in standardized_rdd.take(5):\n",
        "    print(f\"Equipment: {record[0]}, Location: {record[2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-USVEZUlTxgq",
        "outputId": "c8f5d82f-d1a2-4f9c-a9c6-01d6ac7ec978"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location Standardization Examples:\n",
            "Equipment: EQ001, Location: JURONG_IE\n",
            "Equipment: EQ002, Location: TUAS_SOUTH\n",
            "Equipment: EQ003, Location: WOODLANDS_IP\n",
            "Equipment: EQ004, Location: CHANGI_BP\n",
            "Equipment: EQ005, Location: AMK_IP2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Higher Order Functions\n",
        "\n",
        "### Function Composition"
      ],
      "metadata": {
        "id": "1qZVMD_hTyL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compose(*functions):\n",
        "    \"\"\"\n",
        "    Higher-order function that composes multiple functions\n",
        "    compose(f, g, h)(x) = f(g(h(x)))\n",
        "    \"\"\"\n",
        "    def inner(arg):\n",
        "        result = arg\n",
        "        for func in reversed(functions):\n",
        "            result = func(result)\n",
        "        return result\n",
        "    return inner\n",
        "\n",
        "# Individual transformation functions\n",
        "def clean_whitespace(record: tuple) -> tuple:\n",
        "    \"\"\"Remove extra whitespace from all fields\"\"\"\n",
        "    return tuple(field.strip() if isinstance(field, str) else field for field in record)\n",
        "\n",
        "def uppercase_status(record: tuple) -> tuple:\n",
        "    \"\"\"Convert status field to uppercase\"\"\"\n",
        "    record_list = list(record)\n",
        "    if len(record_list) > 6:\n",
        "        record_list[6] = record_list[6].upper()\n",
        "    return tuple(record_list)\n",
        "\n",
        "def add_processing_flag(record: tuple) -> tuple:\n",
        "    \"\"\"Add a processing flag to indicate data has been cleansed\"\"\"\n",
        "    return record + ('CLEANSED',)\n",
        "\n",
        "# Compose all transformation functions\n",
        "full_transform = compose(add_processing_flag, uppercase_status, clean_whitespace)\n",
        "\n",
        "# Apply composed transformation\n",
        "composed_rdd = standardized_rdd.map(full_transform)\n",
        "\n",
        "print(\"Composed Transformation Examples:\")\n",
        "for record in composed_rdd.take(3):\n",
        "    print(f\"Equipment: {record[0]}, Status: {record[6]}, Flag: {record[-1]}\")\n",
        "\n",
        "# 4.2 Filter with Predicate Generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7MflgO2T8iB",
        "outputId": "516c33e3-6a0f-4756-e8c8-1847a9747e95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Composed Transformation Examples:\n",
            "Equipment: EQ001, Status: NORMAL, Flag: CLEANSED\n",
            "Equipment: EQ002, Status: ALERT, Flag: CLEANSED\n",
            "Equipment: EQ003, Status: , Flag: CLEANSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Higher Order Filters with Predicates"
      ],
      "metadata": {
        "id": "j0I-AMahUGSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_temperature_filter(min_temp: float, max_temp: float) -> Callable:\n",
        "    \"\"\"\n",
        "    Higher-order function that returns a filter predicate\n",
        "    for temperature range\n",
        "    \"\"\"\n",
        "    def temperature_predicate(record: tuple) -> bool:\n",
        "        temp = record[4]\n",
        "        if temp is None:\n",
        "            return False\n",
        "        try:\n",
        "            temp_float = float(temp)\n",
        "            return min_temp <= temp_float <= max_temp\n",
        "        except (ValueError, TypeError):\n",
        "            return False\n",
        "    return temperature_predicate\n",
        "\n",
        "# Create different temperature filters\n",
        "normal_temp_filter = create_temperature_filter(60.0, 90.0)\n",
        "high_temp_filter = create_temperature_filter(90.0, 150.0)\n",
        "\n",
        "normal_temp_equipment = composed_rdd.filter(normal_temp_filter)\n",
        "high_temp_equipment = composed_rdd.filter(high_temp_filter)\n",
        "\n",
        "print(f\"Equipment in normal temperature range (60-90°C): {normal_temp_equipment.count()}\")\n",
        "print(f\"Equipment in high temperature range (90-150°C): {high_temp_equipment.count()}\")\n",
        "\n",
        "print(\"\\nHigh Temperature Equipment:\")\n",
        "for record in high_temp_equipment.take(3):\n",
        "    print(f\"  {record[0]} at {record[2]}: {record[4]}°C - Status: {record[6]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiNVkAAMUONX",
        "outputId": "b5c612e6-051a-49fd-a51d-775ad6ad0508"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equipment in normal temperature range (60-90°C): 3\n",
            "Equipment in high temperature range (90-150°C): 2\n",
            "\n",
            "High Temperature Equipment:\n",
            "  EQ005 at AMK_IP2: 92.3°C - Status: WARNING\n",
            "  EQ009 at CHANGI_BP: 95.0°C - Status: WARNING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Map with Transformer Generator"
      ],
      "metadata": {
        "id": "tVEoglQbUV7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_field_transformer(field_index: int, transform_func: Callable) -> Callable:\n",
        "    \"\"\"\n",
        "    Higher-order function that creates a transformer for specific field\n",
        "    \"\"\"\n",
        "    def transformer(record: tuple) -> tuple:\n",
        "        record_list = list(record)\n",
        "        if field_index < len(record_list):\n",
        "            record_list[field_index] = transform_func(record_list[field_index])\n",
        "        return tuple(record_list)\n",
        "    return transformer\n",
        "\n",
        "# Create transformers for specific fields\n",
        "equipment_type_transformer = create_field_transformer(\n",
        "    1,\n",
        "    lambda x: x.replace('-', '_').lower() if x else x\n",
        ")\n",
        "\n",
        "transformed_equipment_rdd = composed_rdd.map(equipment_type_transformer)\n",
        "\n",
        "print(\"Equipment Type Transformation Examples:\")\n",
        "for record in transformed_equipment_rdd.take(3):\n",
        "    print(f\"Equipment ID: {record[0]}, Type: {record[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzskcnMVUiYd",
        "outputId": "dd7f3d13-db1c-4b2c-d3c1-0f35a933a287"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equipment Type Transformation Examples:\n",
            "Equipment ID: EQ001, Type: cnc_milling_001\n",
            "Equipment ID: EQ002, Type: hydraulic_press_042\n",
            "Equipment ID: EQ003, Type: robotic_arm_123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Currying Functions\n",
        "\n",
        "### Curried Alerts"
      ],
      "metadata": {
        "id": "XNm-TH1vUkbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_alert_checker(status_level: str) -> Callable:\n",
        "    \"\"\"\n",
        "    Curried function: takes status level, returns function that checks location\n",
        "    \"\"\"\n",
        "    def check_location(location: str) -> Callable:\n",
        "        \"\"\"\n",
        "        Takes location, returns function that checks equipment record\n",
        "        \"\"\"\n",
        "        def check_record(record: tuple) -> bool:\n",
        "            \"\"\"\n",
        "            Checks if record matches status and location criteria\n",
        "            \"\"\"\n",
        "            return (record[6] == status_level and\n",
        "                    location.upper() in record[2].upper())\n",
        "        return check_record\n",
        "    return check_location\n",
        "\n",
        "# Create curried alert checkers\n",
        "warning_checker = create_alert_checker('WARNING')\n",
        "jurong_warning_checker = warning_checker('JURONG')\n",
        "tuas_warning_checker = warning_checker('TUAS')\n",
        "\n",
        "# Apply filters\n",
        "jurong_warnings = transformed_equipment_rdd.filter(jurong_warning_checker)\n",
        "tuas_warnings = transformed_equipment_rdd.filter(tuas_warning_checker)\n",
        "\n",
        "print(f\"Warnings in Jurong area: {jurong_warnings.count()}\")\n",
        "print(f\"Warnings in Tuas area: {tuas_warnings.count()}\")\n",
        "\n",
        "if jurong_warnings.count() > 0:\n",
        "    print(\"\\nJurong Warning Details:\")\n",
        "    for record in jurong_warnings.collect():\n",
        "        print(f\"  {record[0]} - {record[1]} - {record[7] if len(record) > 7 else 'N/A'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9LXbKndUtXh",
        "outputId": "b1c9430d-ee5e-4048-f7c3-47c250a414e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warnings in Jurong area: 0\n",
            "Warnings in Tuas area: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Curried Temperature Analyser"
      ],
      "metadata": {
        "id": "_M0VIL8fUvAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_temp_analyzer(operation: str) -> Callable:\n",
        "    \"\"\"\n",
        "    Curried function for temperature analysis\n",
        "    operation: 'above', 'below', 'between'\n",
        "    \"\"\"\n",
        "    def with_threshold(threshold: float) -> Callable:\n",
        "        \"\"\"\n",
        "        Takes threshold value\n",
        "        \"\"\"\n",
        "        def analyze(record: tuple) -> bool:\n",
        "            \"\"\"\n",
        "            Analyzes temperature against threshold\n",
        "            \"\"\"\n",
        "            temp = record[4]\n",
        "            if temp is None:\n",
        "                return False\n",
        "\n",
        "            try:\n",
        "                temp_float = float(temp)\n",
        "                if operation == 'above':\n",
        "                    return temp_float > threshold\n",
        "                elif operation == 'below':\n",
        "                    return temp_float < threshold\n",
        "                return False\n",
        "            except (ValueError, TypeError):\n",
        "                return False\n",
        "        return analyze\n",
        "    return with_threshold\n",
        "\n",
        "# Create curried temperature analyzers\n",
        "above_analyzer = create_temp_analyzer('above')\n",
        "above_85_checker = above_analyzer(85.0)\n",
        "\n",
        "critical_temp_equipment = transformed_equipment_rdd.filter(above_85_checker)\n",
        "\n",
        "print(f\"Equipment with temperature above 85°C: {critical_temp_equipment.count()}\")\n",
        "print(\"\\nCritical Temperature Equipment:\")\n",
        "for record in critical_temp_equipment.take(5):\n",
        "    print(f\"  {record[0]} at {record[2]}: {record[4]}°C\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6JO_1_SUzsi",
        "outputId": "9deb7357-e46e-4778-de52-f01564e8b391"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equipment with temperature above 85°C: 4\n",
            "\n",
            "Critical Temperature Equipment:\n",
            "  EQ001 at JURONG_IE: 85.5°C\n",
            "  EQ002 at TUAS_SOUTH: 86.22°C\n",
            "  EQ005 at AMK_IP2: 92.3°C\n",
            "  EQ009 at CHANGI_BP: 95.0°C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Curried Temeprature Scores"
      ],
      "metadata": {
        "id": "exxYxyWoU3Rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_quality_scorer(weight_temp: float) -> Callable:\n",
        "    \"\"\"\n",
        "    Curried function that creates quality scorer with temperature weight\n",
        "    \"\"\"\n",
        "    def with_completeness_weight(weight_complete: float) -> Callable:\n",
        "        \"\"\"\n",
        "        Takes completeness weight, returns scoring function\n",
        "        \"\"\"\n",
        "        def score_record(record: tuple) -> Tuple[str, float]:\n",
        "            \"\"\"\n",
        "            Calculate data quality score for record\n",
        "            \"\"\"\n",
        "            equipment_id = record[0]\n",
        "            score = 0.0\n",
        "\n",
        "            # Temperature validity score\n",
        "            if record[4] is not None:\n",
        "                score += weight_temp\n",
        "\n",
        "            # Completeness score (all fields present)\n",
        "            if all(field for field in record[:7]):\n",
        "                score += weight_complete\n",
        "\n",
        "            # Date validity score\n",
        "            if record[3] is not None:\n",
        "                score += (100 - weight_temp - weight_complete)\n",
        "\n",
        "            return (equipment_id, score)\n",
        "        return score_record\n",
        "    return with_completeness_weight\n",
        "\n",
        "# Create quality scorer with different weightings\n",
        "quality_scorer = create_quality_scorer(40.0)  # 40% weight for temperature\n",
        "with_complete_weight = quality_scorer(30.0)    # 30% weight for completeness\n",
        "# Remaining 30% for date validity\n",
        "\n",
        "quality_scores_rdd = transformed_equipment_rdd.map(with_complete_weight)\n",
        "\n",
        "print(\"Data Quality Scores:\")\n",
        "for eq_id, score in quality_scores_rdd.sortBy(lambda x: x[1], ascending=False).take(5):\n",
        "    print(f\"  {eq_id}: {score:.1f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3gnLI4CU73g",
        "outputId": "090a3334-e172-4a60-f553-874429c0be4b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Quality Scores:\n",
            "  EQ001: 100.0%\n",
            "  EQ002: 100.0%\n",
            "  EQ005: 100.0%\n",
            "  EQ006: 100.0%\n",
            "  EQ009: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping and Aggregates"
      ],
      "metadata": {
        "id": "YaXcquY5VB1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "location_equipment_rdd = transformed_equipment_rdd.map(\n",
        "    lambda record: (record[2], record[0])  # (location, equipment_id)\n",
        ")\n",
        "\n",
        "grouped_by_location = location_equipment_rdd.groupByKey()\n",
        "\n",
        "print(\"Equipment Count by Location:\")\n",
        "for location, equipment_ids in grouped_by_location.collect():\n",
        "    eq_list = list(equipment_ids)\n",
        "    print(f\"  {location}: {len(eq_list)} equipment - {eq_list}\")\n",
        "\n",
        "\n",
        "def extract_location_temp(record: tuple) -> Optional[Tuple[str, Tuple[float, int]]]:\n",
        "    \"\"\"Extract location and temperature for aggregation\"\"\"\n",
        "    location = record[2]\n",
        "    temp = record[4]\n",
        "\n",
        "    if temp is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        temp_float = float(temp)\n",
        "        return (location, (temp_float, 1))\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "location_temp_rdd = transformed_equipment_rdd.map(extract_location_temp).filter(lambda x: x is not None)\n",
        "\n",
        "# Reduce to calculate sum and count\n",
        "temp_aggregates = location_temp_rdd.reduceByKey(\n",
        "    lambda a, b: (a[0] + b[0], a[1] + b[1])\n",
        ")\n",
        "\n",
        "# Calculate averages\n",
        "avg_temp_by_location = temp_aggregates.mapValues(\n",
        "    lambda x: round(x[0] / x[1], 2)\n",
        ")\n",
        "\n",
        "print(\"Average Temperature by Location:\")\n",
        "for location, avg_temp in avg_temp_by_location.sortBy(lambda x: x[1], ascending=False).collect():\n",
        "    print(f\"  {location}: {avg_temp}°C\")\n",
        "valid_temps = transformed_equipment_rdd.map(\n",
        "    lambda r: float(r[4]) if r[4] is not None else None\n",
        ").filter(lambda x: x is not None)\n",
        "\n",
        "if valid_temps.count() > 0:\n",
        "    max_temp = valid_temps.reduce(lambda a, b: max(a, b))\n",
        "    min_temp = valid_temps.reduce(lambda a, b: min(a, b))\n",
        "    total_temp = valid_temps.reduce(lambda a, b: a + b)\n",
        "    avg_temp = total_temp / valid_temps.count()\n",
        "\n",
        "    print(f\"Maximum Temperature: {max_temp}°C\")\n",
        "    print(f\"Minimum Temperature: {min_temp}°C\")\n",
        "    print(f\"Average Temperature: {avg_temp:.2f}°C\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJn7FlWBVIkA",
        "outputId": "1530d9cd-4b2a-44e6-84d9-8c851bc381eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equipment Count by Location:\n",
            "  TUAS_SOUTH: 2 equipment - ['EQ002', 'EQ007']\n",
            "  WOODLANDS_IP: 1 equipment - ['EQ003']\n",
            "  AMK_IP2: 1 equipment - ['EQ005']\n",
            "  JURONG_IE: 2 equipment - ['EQ001', 'EQ006']\n",
            "  CHANGI_BP: 2 equipment - ['EQ004', 'EQ009']\n",
            "Average Temperature by Location:\n",
            "  CHANGI_BP: 95.0°C\n",
            "  AMK_IP2: 92.3°C\n",
            "  TUAS_SOUTH: 86.22°C\n",
            "  WOODLANDS_IP: 78.0°C\n",
            "  JURONG_IE: 54.84°C\n",
            "Maximum Temperature: 95.0°C\n",
            "Minimum Temperature: 24.17°C\n",
            "Average Temperature: 76.86°C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleansing Pipeline"
      ],
      "metadata": {
        "id": "yZ0Rq583VaB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_cleansing_pipeline(raw_data: str) -> Optional[dict]:\n",
        "    \"\"\"\n",
        "    Complete data cleansing pipeline combining all techniques\n",
        "    Returns cleansed record as dictionary or None if invalid\n",
        "    \"\"\"\n",
        "    # Parse\n",
        "    fields = raw_data.split('|')\n",
        "    if len(fields) < 8:\n",
        "        return None\n",
        "\n",
        "    record = tuple(field.strip() for field in fields)\n",
        "\n",
        "    # Validate\n",
        "    if not record[0] or not record[1] or not record[2]:\n",
        "        return None\n",
        "\n",
        "    # Normalize date\n",
        "    normalized_date = normalize_date(record[3])\n",
        "    if normalized_date is None:\n",
        "        return None\n",
        "\n",
        "    # Normalize temperature\n",
        "    temp = record[4]\n",
        "    unit = record[5]\n",
        "    normalized_temp = None\n",
        "\n",
        "    if temp not in ('NULL', '-999', ''):\n",
        "        try:\n",
        "            temp_float = float(temp)\n",
        "            if unit == 'FAHRENHEIT':\n",
        "                temp_float = fahrenheit_to_celsius(temp_float)\n",
        "            if 0 <= temp_float <= 150:\n",
        "                normalized_temp = round(temp_float, 2)\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    # Standardize location\n",
        "    location = standardize_location(record[2])\n",
        "\n",
        "    # Return cleansed record as dictionary\n",
        "    return {\n",
        "        'equipment_id': record[0],\n",
        "        'equipment_type': record[1].replace('-', '_').lower(),\n",
        "        'location': location,\n",
        "        'timestamp': normalized_date,\n",
        "        'temperature_celsius': normalized_temp,\n",
        "        'status': record[6].upper(),\n",
        "        'notes': record[7] if len(record) > 7 else '',\n",
        "        'data_quality': 'HIGH' if normalized_temp is not None else 'MEDIUM'\n",
        "    }\n",
        "\n",
        "# Apply complete pipeline\n",
        "cleansed_rdd = equipment_rdd.map(complete_cleansing_pipeline).filter(lambda x: x is not None)\n",
        "\n",
        "print(f\"\\nTotal cleansed records: {cleansed_rdd.count()}\")\n",
        "print(\"\\nCleansed Data Sample:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for record in cleansed_rdd.take(5):\n",
        "    print(f\"Equipment ID: {record['equipment_id']}\")\n",
        "    print(f\"  Type: {record['equipment_type']}\")\n",
        "    print(f\"  Location: {record['location']}\")\n",
        "    print(f\"  Timestamp: {record['timestamp']}\")\n",
        "    print(f\"  Temperature: {record['temperature_celsius']}°C\")\n",
        "    print(f\"  Status: {record['status']}\")\n",
        "    print(f\"  Data Quality: {record['data_quality']}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeD-8OFaVcs1",
        "outputId": "31b08366-56cb-4596-a5e8-f9e6e307c19c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total cleansed records: 8\n",
            "\n",
            "Cleansed Data Sample:\n",
            "--------------------------------------------------------------------------------\n",
            "Equipment ID: EQ001\n",
            "  Type: cnc_milling_001\n",
            "  Location: JURONG_IE\n",
            "  Timestamp: 2024-12-25 14:30\n",
            "  Temperature: 85.5°C\n",
            "  Status: NORMAL\n",
            "  Data Quality: HIGH\n",
            "\n",
            "Equipment ID: EQ002\n",
            "  Type: hydraulic_press_042\n",
            "  Location: TUAS_SOUTH\n",
            "  Timestamp: 2024-12-25 15:45\n",
            "  Temperature: 86.22°C\n",
            "  Status: ALERT\n",
            "  Data Quality: HIGH\n",
            "\n",
            "Equipment ID: EQ003\n",
            "  Type: robotic_arm_123\n",
            "  Location: WOODLANDS_IP\n",
            "  Timestamp: 2024-12-25 16:00\n",
            "  Temperature: 78.0°C\n",
            "  Status: \n",
            "  Data Quality: HIGH\n",
            "\n",
            "Equipment ID: EQ004\n",
            "  Type: injection_mold_099\n",
            "  Location: CHANGI_BP\n",
            "  Timestamp: 2024-12-25 16:15\n",
            "  Temperature: None°C\n",
            "  Status: NORMAL\n",
            "  Data Quality: MEDIUM\n",
            "\n",
            "Equipment ID: EQ005\n",
            "  Type: lathe_machine_067\n",
            "  Location: AMK_IP2\n",
            "  Timestamp: 2024-12-25 17:00\n",
            "  Temperature: 92.3°C\n",
            "  Status: WARNING\n",
            "  Data Quality: HIGH\n",
            "\n"
          ]
        }
      ]
    }
  ]
}