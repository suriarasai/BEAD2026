{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN13tjX2tqEmtM9IHJQJPH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suriarasai/BEAD2026/blob/main/colab/03c_PySpark_RDD_Practice_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark RDD Exercises: Functional Programming Concepts\n",
        "Here are 10 exercises focusing on RDD operations to learn functional programming principles. Each exercise includes the problem, solution, and detailed explanation."
      ],
      "metadata": {
        "id": "JxF9ZwDqCg-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup\n",
        "Here are 10 exercises focusing on RDD operations to learn functional programming principles. Each exercise includes the problem, solution, and detailed explanation."
      ],
      "metadata": {
        "id": "KKnkzwe7Crh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup"
      ],
      "metadata": {
        "id": "uxzn0x7BCyqV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cRF_RvulCHvF"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from functools import reduce\n",
        "import math\n",
        "\n",
        "# Initialize SparkContext\n",
        "conf = SparkConf().setAppName(\"FunctionalProgrammingExercises\")\n",
        "sc = SparkContext.getOrCreate(conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1: Pure vs Impure Functions\n",
        "The impure function tries to modify global state (multiplier) and append to a list (results_list). In distributed computing, each worker has its own copy of these variables, so changes aren't synchronized. The pure function takes all needed parameters and returns results based solely on inputs, making it safe for parallel execution."
      ],
      "metadata": {
        "id": "AFGwUQmyC5yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "numbers_rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
        "\n",
        "# IMPURE FUNCTION (BAD)\n",
        "multiplier = 2  # External state\n",
        "results_list = []  # External mutable state\n",
        "\n",
        "def impure_multiply(x):\n",
        "    global multiplier\n",
        "    multiplier += 1  # Modifying external state - DANGEROUS!\n",
        "    results_list.append(x)  # Side effect - WON'T WORK in distributed setting\n",
        "    return x * multiplier\n",
        "\n",
        "# PURE FUNCTION (GOOD)\n",
        "def pure_multiply(x, factor=2):\n",
        "    \"\"\"Output depends only on input - no side effects\"\"\"\n",
        "    return x * factor\n",
        "\n",
        "# Apply impure function (problematic)\n",
        "impure_result = numbers_rdd.map(impure_multiply).collect()\n",
        "print(f\"Impure result: {impure_result}\")\n",
        "print(f\"Multiplier after (unreliable): {multiplier}\")\n",
        "print(f\"Results list (empty/incomplete): {results_list}\")\n",
        "\n",
        "# Reset for comparison\n",
        "multiplier = 2\n",
        "\n",
        "\n",
        "# Apply pure function (reliable)\n",
        "pure_result = numbers_rdd.map(lambda x: pure_multiply(x, 2)).collect()\n",
        "print(f\"Pure result: {pure_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pObCQHTC9qV",
        "outputId": "856fb753-e390-4956-8b12-29a7339530dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Impure result: [3, 8, 9, 16, 25]\n",
            "Multiplier after (unreliable): 2\n",
            "Results list (empty/incomplete): []\n",
            "Pure result: [2, 4, 6, 8, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: Map with Complex Pure Functions\n",
        "\n",
        "The pure function encapsulates all logic internally, making it testable, reusable, and guaranteed to produce the same output for the same input. This predictability is crucial in distributed systems."
      ],
      "metadata": {
        "id": "L-hH3c2zDCv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "celsius_rdd = sc.parallelize([0, 10, 20, 30, 40])\n",
        "\n",
        "def temperature_analysis(celsius):\n",
        "    \"\"\"\n",
        "    Pure function: No external dependencies, deterministic output\n",
        "    \"\"\"\n",
        "    fahrenheit = (celsius * 9/5) + 32\n",
        "\n",
        "    # Categorization logic encapsulated within function\n",
        "    if fahrenheit < 50:\n",
        "        category = \"cold\"\n",
        "    elif fahrenheit < 77:\n",
        "        category = \"mild\"\n",
        "    else:\n",
        "        category = \"hot\"\n",
        "\n",
        "    return (celsius, fahrenheit, category)\n",
        "\n",
        "# Apply the pure function\n",
        "result = celsius_rdd.map(temperature_analysis).collect()\n",
        "for item in result:\n",
        "    print(f\"Celsius: {item[0]}°C, Fahrenheit: {item[1]}°F, Category: {item[2]}\")\n",
        "\n",
        "# Demonstrate determinism - running again gives same results\n",
        "result2 = celsius_rdd.map(temperature_analysis).collect()\n",
        "print(f\"\\nResults are identical: {result == result2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBTC4H38DGLr",
        "outputId": "7ca187cf-8843-4c78-e628-5c3e04c0c3fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Celsius: 0°C, Fahrenheit: 32.0°F, Category: cold\n",
            "Celsius: 10°C, Fahrenheit: 50.0°F, Category: mild\n",
            "Celsius: 20°C, Fahrenheit: 68.0°F, Category: mild\n",
            "Celsius: 30°C, Fahrenheit: 86.0°F, Category: hot\n",
            "Celsius: 40°C, Fahrenheit: 104.0°F, Category: hot\n",
            "\n",
            "Results are identical: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3: Filter with Functional Predicates\n",
        "Pure predicate functions return boolean values based solely on input. They can be composed, tested independently, and reused across different RDDs without side effects."
      ],
      "metadata": {
        "id": "gpnRPk5BDJth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numbers_rdd = sc.parallelize(range(1, 21))\n",
        "\n",
        "# Pure predicate functions\n",
        "def is_even(n):\n",
        "    \"\"\"Pure predicate: checks if number is even\"\"\"\n",
        "    return n % 2 == 0\n",
        "\n",
        "def is_prime(n):\n",
        "    \"\"\"Pure predicate: checks if number is prime\"\"\"\n",
        "    if n < 2:\n",
        "        return False\n",
        "    for i in range(2, int(math.sqrt(n)) + 1):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_divisible_by_3_or_5(n):\n",
        "    \"\"\"Pure predicate: checks divisibility\"\"\"\n",
        "    return n % 3 == 0 or n % 5 == 0\n",
        "\n",
        "# Apply filters\n",
        "even_numbers = numbers_rdd.filter(is_even).collect()\n",
        "prime_numbers = numbers_rdd.filter(is_prime).collect()\n",
        "div_3_or_5 = numbers_rdd.filter(is_divisible_by_3_or_5).collect()\n",
        "\n",
        "print(f\"Even numbers: {even_numbers}\")\n",
        "print(f\"Prime numbers: {prime_numbers}\")\n",
        "print(f\"Divisible by 3 or 5: {div_3_or_5}\")\n",
        "\n",
        "# Demonstrate function composition\n",
        "def compose_predicates(pred1, pred2):\n",
        "    \"\"\"Higher-order function to compose predicates\"\"\"\n",
        "    return lambda x: pred1(x) and pred2(x)\n",
        "\n",
        "# Even AND prime (only 2)\n",
        "even_and_prime = compose_predicates(is_even, is_prime)\n",
        "result = numbers_rdd.filter(even_and_prime).collect()\n",
        "print(f\"Even and prime: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg_MqOExDMUN",
        "outputId": "adf59ac1-c352-4ab6-db0a-e667aa95d056"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Even numbers: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
            "Prime numbers: [2, 3, 5, 7, 11, 13, 17, 19]\n",
            "Divisible by 3 or 5: [3, 5, 6, 9, 10, 12, 15, 18, 20]\n",
            "Even and prime: [2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4: Reduce Operations without State\n",
        "Reduce operations require pure, associative functions. The order of operations might vary in distributed computing, so (a op b) op c must equal a op (b op c) for consistent results."
      ],
      "metadata": {
        "id": "Z5FPXX79DToe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numbers_rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
        "\n",
        "# Pure reduction functions\n",
        "def add(x, y):\n",
        "    \"\"\"Pure function: adds two numbers\"\"\"\n",
        "    return x + y\n",
        "\n",
        "def multiply(x, y):\n",
        "    \"\"\"Pure function: multiplies two numbers\"\"\"\n",
        "    return x * y\n",
        "\n",
        "def find_max(x, y):\n",
        "    \"\"\"Pure function: returns maximum\"\"\"\n",
        "    return x if x > y else y\n",
        "\n",
        "def find_min(x, y):\n",
        "    \"\"\"Pure function: returns minimum\"\"\"\n",
        "    return x if x < y else y\n",
        "\n",
        "# Apply reductions\n",
        "sum_result = numbers_rdd.reduce(add)\n",
        "product_result = numbers_rdd.reduce(multiply)\n",
        "max_result = numbers_rdd.reduce(find_max)\n",
        "min_result = numbers_rdd.reduce(find_min)\n",
        "\n",
        "print(f\"Sum: {sum_result}\")\n",
        "print(f\"Product: {product_result}\")\n",
        "print(f\"Max: {max_result}\")\n",
        "print(f\"Min: {min_result}\")\n",
        "\n",
        "# Alternative: Using lambda functions (also pure)\n",
        "sum_lambda = numbers_rdd.reduce(lambda x, y: x + y)\n",
        "product_lambda = numbers_rdd.reduce(lambda x, y: x * y)\n",
        "\n",
        "print(f\"\\nUsing lambdas - Sum: {sum_lambda}, Product: {product_lambda}\")\n",
        "\n",
        "# Demonstrate associativity importance\n",
        "def non_associative_op(x, y):\n",
        "    \"\"\"Non-associative operation - problematic for reduce\"\"\"\n",
        "    return (x - y) * 2\n",
        "\n",
        "# This gives unpredictable results in distributed setting!\n",
        "# result = numbers_rdd.reduce(non_associative_op)  # Don't rely on this!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwCoMJYJDWmy",
        "outputId": "11908f4f-1df4-41f2-b174-a86d85a37f59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum: 15\n",
            "Product: 120\n",
            "Max: 5\n",
            "Min: 1\n",
            "\n",
            "Using lambdas - Sum: 15, Product: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 5: FlatMap for Functional Transformations\n",
        "FlatMap applies a function that returns an iterable, then flattens the results. Using pure functions ensures each sentence is processed independently without side effects."
      ],
      "metadata": {
        "id": "lcZERZKzDaS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_rdd = sc.parallelize([\n",
        "    \"Hello world\",\n",
        "    \"Functional programming rocks\",\n",
        "    \"Pure functions scale\"\n",
        "])\n",
        "\n",
        "def tokenize(sentence):\n",
        "    \"\"\"Pure function: splits sentence into words\"\"\"\n",
        "    return sentence.lower().split()\n",
        "\n",
        "def word_with_length(sentence):\n",
        "    \"\"\"Pure function: returns list of (word, length) tuples\"\"\"\n",
        "    return [(word, len(word)) for word in sentence.lower().split()]\n",
        "\n",
        "def generate_bigrams(sentence):\n",
        "    \"\"\"Pure function: generates 2-grams from sentence\"\"\"\n",
        "    words = sentence.lower().split()\n",
        "    return [f\"{words[i]}_{words[i+1]}\"\n",
        "            for i in range(len(words)-1)] if len(words) > 1 else []\n",
        "\n",
        "# Apply flatMap operations\n",
        "words = sentences_rdd.flatMap(tokenize).collect()\n",
        "print(f\"All words: {words}\")\n",
        "\n",
        "word_lengths = sentences_rdd.flatMap(word_with_length).collect()\n",
        "print(f\"Words with lengths: {word_lengths}\")\n",
        "\n",
        "bigrams = sentences_rdd.flatMap(generate_bigrams).collect()\n",
        "print(f\"Bigrams: {bigrams}\")\n",
        "\n",
        "# Chaining operations functionally\n",
        "word_count = (sentences_rdd\n",
        "    .flatMap(tokenize)\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        "    .collect())\n",
        "print(f\"Word counts: {word_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB1VEJuLDc98",
        "outputId": "9762c632-174a-4223-ca31-2f085f6e8429"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All words: ['hello', 'world', 'functional', 'programming', 'rocks', 'pure', 'functions', 'scale']\n",
            "Words with lengths: [('hello', 5), ('world', 5), ('functional', 10), ('programming', 11), ('rocks', 5), ('pure', 4), ('functions', 9), ('scale', 5)]\n",
            "Bigrams: ['hello_world', 'functional_programming', 'programming_rocks', 'pure_functions', 'functions_scale']\n",
            "Word counts: [('hello', 1), ('world', 1), ('functional', 1), ('programming', 1), ('rocks', 1), ('pure', 1), ('functions', 1), ('scale', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6: Avoiding Shared Mutable State\n",
        "\n",
        "Instead of maintaining mutable state, we use pure functions that return values representing counts. These can be safely combined using reduce operations."
      ],
      "metadata": {
        "id": "gTt_uXLGDh_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numbers_rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Using Filters and Count\n",
        "\n",
        "def is_even(x):\n",
        "    return x % 2 == 0\n",
        "\n",
        "def is_odd(x):\n",
        "    return x % 2 != 0\n",
        "\n",
        "even_count = numbers_rdd.filter(is_even).count()\n",
        "odd_count = numbers_rdd.filter(is_odd).count()\n",
        "\n",
        "print(f\"Approach 1 - Even: {even_count}, Odd: {odd_count}\")\n",
        "\n",
        "#  Using map and reduce\n",
        "def classify_number(x):\n",
        "    \"\"\"Pure function: returns (even_count, odd_count) tuple\"\"\"\n",
        "    if x % 2 == 0:\n",
        "        return (1, 0)  # even\n",
        "    else:\n",
        "        return (0, 1)  # odd\n",
        "\n",
        "def combine_counts(count1, count2):\n",
        "    \"\"\"Pure function: combines two count tuples\"\"\"\n",
        "    return (count1[0] + count2[0], count1[1] + count2[1])\n",
        "\n",
        "result = numbers_rdd.map(classify_number).reduce(combine_counts)\n",
        "print(f\"Approach 2 - Even: {result[0]}, Odd: {result[1]}\")\n",
        "\n",
        "# Using partition\n",
        "def partition_even_odd(iterator):\n",
        "    \"\"\"Pure function: partitions numbers in an iterator\"\"\"\n",
        "    even = []\n",
        "    odd = []\n",
        "    for num in iterator:\n",
        "        if num % 2 == 0:\n",
        "            even.append(num)\n",
        "        else:\n",
        "            odd.append(num)\n",
        "    return [(len(even), len(odd))]\n",
        "\n",
        "result = numbers_rdd.mapPartitions(partition_even_odd).reduce(combine_counts)\n",
        "print(f\"Approach 3 - Even: {result[0]}, Odd: {result[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjFbEmm6Dlv-",
        "outputId": "bf13d72e-37cb-45a3-d33f-d409f6546c07"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approach 1 - Even: 5, Odd: 5\n",
            "Approach 2 - Even: 5, Odd: 5\n",
            "Approach 3 - Even: 5, Odd: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7: Function Composition and Pipelining\n",
        "\n",
        "Function composition allows building complex transformations from simple, pure functions. Each function in the pipeline is independent and testable."
      ],
      "metadata": {
        "id": "Dls9wCP2DovI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_rdd = sc.parallelize([\n",
        "    \"  HELLO world  \",\n",
        "    \"PYTHON programming\",\n",
        "    \"spark FUNCTIONAL\"\n",
        "])\n",
        "\n",
        "# Individual pure functions\n",
        "def strip_whitespace(text):\n",
        "    \"\"\"Pure: removes leading/trailing whitespace\"\"\"\n",
        "    return text.strip()\n",
        "\n",
        "def to_lowercase(text):\n",
        "    \"\"\"Pure: converts to lowercase\"\"\"\n",
        "    return text.lower()\n",
        "\n",
        "def reverse_string(text):\n",
        "    \"\"\"Pure: reverses string\"\"\"\n",
        "    return text[::-1]\n",
        "\n",
        "def add_prefix(prefix):\n",
        "    \"\"\"Pure: returns a function that adds prefix\"\"\"\n",
        "    return lambda text: f\"{prefix}_{text}\"\n",
        "\n",
        "# Function composition helper\n",
        "def compose(*functions):\n",
        "    \"\"\"Compose multiple functions into one\"\"\"\n",
        "    def inner(arg):\n",
        "        result = arg\n",
        "        for func in functions:\n",
        "            result = func(result)\n",
        "        return result\n",
        "    return inner\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = compose(\n",
        "    strip_whitespace,\n",
        "    to_lowercase,\n",
        "    reverse_string,\n",
        "    add_prefix(\"processed\")\n",
        ")\n",
        "\n",
        "# Apply pipeline\n",
        "result = text_rdd.map(pipeline).collect()\n",
        "for item in result:\n",
        "    print(item)\n",
        "\n",
        "# Alternative: Manual chaining (also functional)\n",
        "result2 = (text_rdd\n",
        "    .map(strip_whitespace)\n",
        "    .map(to_lowercase)\n",
        "    .map(reverse_string)\n",
        "    .map(add_prefix(\"processed\"))\n",
        "    .collect())\n",
        "\n",
        "print(f\"\\nResults identical: {result == result2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj2IFXy_DrqB",
        "outputId": "f382bd22-524c-4101-c152-04a6536d0a82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed_dlrow olleh\n",
            "processed_gnimmargorp nohtyp\n",
            "processed_lanoitcnuf kraps\n",
            "\n",
            "Results identical: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 8: Using Accumulators Correctly\n",
        "\n",
        "While accumulators provide a way to track metrics, pure functional approaches using map and reduce are often cleaner and more reliable. Accumulators should be used sparingly and only when necessary."
      ],
      "metadata": {
        "id": "9b7028eYD1ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_rdd = sc.parallelize([10, -5, 20, -3, 15, 0, -10, 25])\n",
        "\n",
        "# Create accumulators (Spark's way of handling distributed state)\n",
        "positive_acc = sc.accumulator(0)\n",
        "negative_acc = sc.accumulator(0)\n",
        "zero_acc = sc.accumulator(0)\n",
        "\n",
        "def process_and_count(x):\n",
        "    \"\"\"\n",
        "    Pure function for transformation,\n",
        "    with side effect for counting (using accumulators)\n",
        "    \"\"\"\n",
        "    # Side effects using accumulators (safe in Spark)\n",
        "    if x > 0:\n",
        "        positive_acc.add(1)\n",
        "    elif x < 0:\n",
        "        negative_acc.add(1)\n",
        "    else:\n",
        "        zero_acc.add(1)\n",
        "\n",
        "    # Pure transformation\n",
        "    return x * 2\n",
        "\n",
        "# Process data\n",
        "transformed = data_rdd.map(process_and_count).collect()\n",
        "\n",
        "print(f\"Transformed data: {transformed}\")\n",
        "print(f\"Positive numbers: {positive_acc.value}\")\n",
        "print(f\"Negative numbers: {negative_acc.value}\")\n",
        "print(f\"Zeros: {zero_acc.value}\")\n",
        "\n",
        "# BETTER APPROACH: Pure functional without accumulators\n",
        "def categorize(x):\n",
        "    \"\"\"Pure function: categorizes number\"\"\"\n",
        "    if x > 0:\n",
        "        return (\"positive\", 1)\n",
        "    elif x < 0:\n",
        "        return (\"negative\", 1)\n",
        "    else:\n",
        "        return (\"zero\", 1)\n",
        "\n",
        "# Count by category using pure functions\n",
        "counts = (data_rdd\n",
        "    .map(categorize)\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        "    .collectAsMap())\n",
        "\n",
        "print(f\"\\nPure functional approach: {counts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4tSXyjnD3hH",
        "outputId": "9af1bed0-59bf-4577-df29-4f4c1aa6e1f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data: [20, -10, 40, -6, 30, 0, -20, 50]\n",
            "Positive numbers: 4\n",
            "Negative numbers: 3\n",
            "Zeros: 1\n",
            "\n",
            "Pure functional approach: {'positive': 4, 'negative': 3, 'zero': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 9: Handling Complex Data with Pure Functions\n",
        "\n",
        "Pure functions can work with complex data structures. Each function transforms data without modifying the original, maintaining immutability."
      ],
      "metadata": {
        "id": "NysIHhUXEFEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_rdd = sc.parallelize([\n",
        "    {\"id\": 1, \"amount\": 100, \"type\": \"credit\"},\n",
        "    {\"id\": 2, \"amount\": 50, \"type\": \"debit\"},\n",
        "    {\"id\": 3, \"amount\": 200, \"type\": \"credit\"},\n",
        "    {\"id\": 4, \"amount\": 75, \"type\": \"debit\"}\n",
        "])\n",
        "\n",
        "def calculate_signed_amount(transaction):\n",
        "    \"\"\"Pure function: returns signed amount based on type\"\"\"\n",
        "    amount = transaction[\"amount\"]\n",
        "    if transaction[\"type\"] == \"credit\":\n",
        "        return amount\n",
        "    else:\n",
        "        return -amount\n",
        "\n",
        "def extract_amount(transaction):\n",
        "    \"\"\"Pure function: extracts amount\"\"\"\n",
        "    return transaction[\"amount\"]\n",
        "\n",
        "def transaction_to_type_amount(transaction):\n",
        "    \"\"\"Pure function: returns (type, amount) tuple\"\"\"\n",
        "    return (transaction[\"type\"], transaction[\"amount\"])\n",
        "\n",
        "def max_transaction(t1, t2):\n",
        "    \"\"\"Pure function: returns transaction with larger amount\"\"\"\n",
        "    return t1 if t1[\"amount\"] > t2[\"amount\"] else t2\n",
        "\n",
        "# 1. Calculate net balance\n",
        "net_balance = transactions_rdd.map(calculate_signed_amount).reduce(lambda a, b: a + b)\n",
        "print(f\"Net balance: {net_balance}\")\n",
        "\n",
        "# 2. Find largest transaction\n",
        "largest = transactions_rdd.reduce(max_transaction)\n",
        "print(f\"Largest transaction: {largest}\")\n",
        "\n",
        "# 3. Group by type and sum\n",
        "type_sums = (transactions_rdd\n",
        "    .map(transaction_to_type_amount)\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        "    .collectAsMap())\n",
        "print(f\"Sum by type: {type_sums}\")\n",
        "\n",
        "# Bonus: Create summary using pure functions\n",
        "def create_summary(transaction):\n",
        "    \"\"\"Pure function: creates transaction summary\"\"\"\n",
        "    signed = calculate_signed_amount(transaction)\n",
        "    return {\n",
        "        \"id\": transaction[\"id\"],\n",
        "        \"signed_amount\": signed,\n",
        "        \"is_credit\": transaction[\"type\"] == \"credit\"\n",
        "    }\n",
        "\n",
        "summaries = transactions_rdd.map(create_summary).collect()\n",
        "for summary in summaries:\n",
        "    print(f\"Transaction {summary['id']}: {summary['signed_amount']} (Credit: {summary['is_credit']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU6b8HaYEK8c",
        "outputId": "7f4f7e35-5359-4c6a-ee2b-22de8e9f2fce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net balance: 175\n",
            "Largest transaction: {'id': 3, 'amount': 200, 'type': 'credit'}\n",
            "Sum by type: {'debit': 125, 'credit': 300}\n",
            "Transaction 1: 100 (Credit: True)\n",
            "Transaction 2: -50 (Credit: False)\n",
            "Transaction 3: 200 (Credit: True)\n",
            "Transaction 4: -75 (Credit: False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 10: Combining Multiple RDDs Functionally\n",
        "\n",
        "oining RDDs and applying transformations using pure functions ensures that operations are deterministic and can be parallelized safely. The functional pipeline approach makes the data flow clear and maintainable."
      ],
      "metadata": {
        "id": "I4dfYbwJEVZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "products_rdd = sc.parallelize([\n",
        "    (1, \"Laptop\"),\n",
        "    (2, \"Mouse\"),\n",
        "    (3, \"Keyboard\")\n",
        "])\n",
        "\n",
        "sales_rdd = sc.parallelize([\n",
        "    (1, 1200),\n",
        "    (2, 25),\n",
        "    (3, 75),\n",
        "    (1, 1200),\n",
        "    (2, 25)\n",
        "])\n",
        "\n",
        "def add_amounts(amount1, amount2):\n",
        "    \"\"\"Pure function: adds two amounts\"\"\"\n",
        "    return amount1 + amount2\n",
        "\n",
        "def apply_discount(amount, discount_rate=0.1):\n",
        "    \"\"\"Pure function: applies discount\"\"\"\n",
        "    return amount * (1 - discount_rate)\n",
        "\n",
        "def format_result(product_sales):\n",
        "    \"\"\"Pure function: formats the result\"\"\"\n",
        "    product_id, (name, total) = product_sales\n",
        "    return {\n",
        "        \"id\": product_id,\n",
        "        \"name\": name,\n",
        "        \"total_sales\": total,\n",
        "        \"after_discount\": apply_discount(total)\n",
        "    }\n",
        "\n",
        "# Step 1: Calculate total sales per product\n",
        "sales_totals = sales_rdd.reduceByKey(add_amounts)\n",
        "print(\"Sales totals:\")\n",
        "for item in sales_totals.collect():\n",
        "    print(f\"  Product {item[0]}: ${item[1]}\")\n",
        "\n",
        "# Step 2: Join with product names\n",
        "joined = products_rdd.join(sales_totals)\n",
        "print(\"\\nJoined data:\")\n",
        "for item in joined.collect():\n",
        "    print(f\"  {item}\")\n",
        "\n",
        "# Step 3: Apply transformations and format\n",
        "final_results = joined.map(format_result).collect()\n",
        "print(\"\\nFinal results with discount:\")\n",
        "for result in final_results:\n",
        "    print(f\"  {result['name']}: ${result['total_sales']} (${result['after_discount']} after discount)\")\n",
        "\n",
        "# Alternative: Functional pipeline approach\n",
        "def create_sales_pipeline(products, sales):\n",
        "    \"\"\"Pure function: creates complete pipeline\"\"\"\n",
        "    return (sales\n",
        "        .reduceByKey(add_amounts)\n",
        "        .join(products)\n",
        "        .map(lambda x: (x[0], x[1][1], x[1][0]))  # (id, name, total)\n",
        "        .map(lambda x: (x[1], x[2], apply_discount(x[2])))\n",
        "        .collect())\n",
        "\n",
        "# Reset RDDs for pipeline\n",
        "products_rdd = sc.parallelize([(1, \"Laptop\"), (2, \"Mouse\"), (3, \"Keyboard\")])\n",
        "sales_rdd = sc.parallelize([(1, 1200), (2, 25), (3, 75), (1, 1200), (2, 25)])\n",
        "\n",
        "pipeline_result = create_sales_pipeline(products_rdd, sales_rdd)\n",
        "print(\"\\nPipeline results:\")\n",
        "for name, total, discounted in pipeline_result:\n",
        "    print(f\"  {name}: ${total} -> ${discounted}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH5LOlJ_EYPk",
        "outputId": "867a50a4-d893-4921-e71b-51e108b3958c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales totals:\n",
            "  Product 2: $50\n",
            "  Product 1: $2400\n",
            "  Product 3: $75\n",
            "\n",
            "Joined data:\n",
            "  (1, ('Laptop', 2400))\n",
            "  (2, ('Mouse', 50))\n",
            "  (3, ('Keyboard', 75))\n",
            "\n",
            "Final results with discount:\n",
            "  Laptop: $2400 ($2160.0 after discount)\n",
            "  Mouse: $50 ($45.0 after discount)\n",
            "  Keyboard: $75 ($67.5 after discount)\n",
            "\n",
            "Pipeline results:\n",
            "  Laptop: $2400 -> $2160.0\n",
            "  Mouse: $50 -> $45.0\n",
            "  Keyboard: $75 -> $67.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Takeaways\n",
        "\n",
        "\n",
        "1. Pure functions are essential for distributed computing - they guarantee consistent results regardless of execution order or location.\n",
        "2. Avoid global state - It won't work correctly in distributed settings and makes code unpredictable.\n",
        "3. Immutability - RDD transformations create new RDDs rather than modifying existing ones.\n",
        "4. Function composition - Build complex operations from simple, testable pure functions.\n",
        "5. Use Spark's mechanisms - When you need state-like behavior, use accumulators or aggregations, not global variables.\n",
        "6. Think in transformations - Express operations as chains of pure transformations rather than imperative steps.\n",
        "\n",
        "Functional programming in PySpark isn't just about style - it's about writing correct, scalable, and maintainable distributed programs."
      ],
      "metadata": {
        "id": "q4zyOEOFHz5X"
      }
    }
  ]
}